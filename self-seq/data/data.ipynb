{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "alpaca_path = 'alpaca/alpaca-cleaned_34493.jsonl'\n",
    "alpaca = pd.read_json(alpaca_path, lines=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17246 17247\n"
     ]
    }
   ],
   "source": [
    "# sample 400\n",
    "# split into half for alpaca\n",
    "alpaca_1 = alpaca.sample(len(alpaca)//2)\n",
    "alpaca_2 = alpaca.drop(alpaca_1.index)\n",
    "print(len(alpaca_1), len(alpaca_2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save as alpaca_split_1 and alpaca_split_2\n",
    "alpaca_1.to_json('alpaca/alpaca-split_1.jsonl', orient='records', lines=True)\n",
    "alpaca_2.to_json('alpaca/alpaca-split_2.jsonl', orient='records', lines=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mkdir an folder called alpaca_test and create two file with 250 samples each\n",
    "alpaca_test1 = alpaca.iloc[:250]\n",
    "alpaca_test2 = alpaca.iloc[250:]\n",
    "import os\n",
    "os.makedirs('alpaca_test', exist_ok=True)\n",
    "alpaca_test1.to_json('alpaca_test/alpaca_test1.jsonl', lines=True, orient='records')\n",
    "alpaca_test2.to_json('alpaca_test/alpaca_test2.jsonl', lines=True, orient='records')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5000 5000 5000\n"
     ]
    }
   ],
   "source": [
    "flancot_path = 'flancot_split/flancot_filtered_15k.jsonl'\n",
    "flancot = pd.read_json(flancot_path, lines=True)\n",
    "# split it into three parts\n",
    "flancot_1 = flancot.sample(len(flancot)//3)\n",
    "flancot_2 = flancot.drop(flancot_1.index).sample(len(flancot)//3)\n",
    "flancot_3 = flancot.drop(flancot_1.index).drop(flancot_2.index)\n",
    "print(len(flancot_1), len(flancot_2), len(flancot_3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save as flancot_split_1, flancot_split_2, flancot_split_3\n",
    "flancot_1.to_json('flancot_split/flancot_split_0.jsonl', orient='records', lines=True)\n",
    "flancot_2.to_json('flancot_split/flancot_split_1.jsonl', orient='records', lines=True)\n",
    "flancot_3.to_json('flancot_split/flancot_split_2.jsonl', orient='records', lines=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "command_r_plus_data = [\n",
    "    \"alpaca/alpaca-split_0-c4ai-command-r-plus-GPTQ.jsonl\",\n",
    "    \"alpaca/alpaca-split_1-c4ai-command-r-plus-GPTQ.jsonl\",\n",
    "    \"alpaca/alpaca-split_2-c4ai-command-r-plus-GPTQ.jsonl\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load them into pandas\n",
    "alpaca_split_0 = pd.read_json(command_r_plus_data[0], lines=True)\n",
    "alpaca_split_1 = pd.read_json(command_r_plus_data[1], lines=True)\n",
    "alpaca_split_2 = pd.read_json(command_r_plus_data[2], lines=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "option\n",
       "A     4.60%\n",
       "B    26.22%\n",
       "C    38.65%\n",
       "D    30.53%\n",
       "Name: count, dtype: object"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# concatenate them\n",
    "alpaca_split = pd.concat([alpaca_split_0, alpaca_split_1, alpaca_split_2], ignore_index=True)\n",
    "# count the option counts\n",
    "option_counts = alpaca_split['option'].value_counts() / len(alpaca_split) * 100 # percentage\n",
    "# add a precentage sign\n",
    "option_counts = option_counts.apply(lambda x: f\"{x:.2f}%\")\n",
    "# sort by ['A', 'B', 'C', 'D']\n",
    "option_counts = option_counts.reindex(['A', 'B', 'C', 'D'])\n",
    "option_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "option\n",
       "A     7.35%\n",
       "B    52.08%\n",
       "C    23.95%\n",
       "D    16.62%\n",
       "Name: count, dtype: object"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llama_3_70b_split_0 = pd.read_json('alpaca/alpaca-split_0-Meta-Llama-3-70B-Instruct.jsonl', lines=True)\n",
    "\n",
    "option_counts = llama_3_70b_split_0['option'].value_counts() / len(llama_3_70b_split_0) * 100\n",
    "option_counts = option_counts.apply(lambda x: f\"{x:.2f}%\")\n",
    "option_counts = option_counts.reindex(['A', 'B', 'C', 'D'])\n",
    "option_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "robust",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "alpaca_path = 'alpaca/alpaca-cleaned_34493.jsonl'\n",
    "alpaca = pd.read_json(alpaca_path, lines=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17246 17247\n"
     ]
    }
   ],
   "source": [
    "# sample 400\n",
    "# split into half for alpaca\n",
    "alpaca_1 = alpaca.sample(len(alpaca)//2)\n",
    "alpaca_2 = alpaca.drop(alpaca_1.index)\n",
    "print(len(alpaca_1), len(alpaca_2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save as alpaca_split_1 and alpaca_split_2\n",
    "alpaca_1.to_json('alpaca/alpaca-split_1.jsonl', orient='records', lines=True)\n",
    "alpaca_2.to_json('alpaca/alpaca-split_2.jsonl', orient='records', lines=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mkdir an folder called alpaca_test and create two file with 250 samples each\n",
    "alpaca_test1 = alpaca.iloc[:250]\n",
    "alpaca_test2 = alpaca.iloc[250:]\n",
    "import os\n",
    "os.makedirs('alpaca_test', exist_ok=True)\n",
    "alpaca_test1.to_json('alpaca_test/alpaca_test1.jsonl', lines=True, orient='records')\n",
    "alpaca_test2.to_json('alpaca_test/alpaca_test2.jsonl', lines=True, orient='records')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5000 5000 5000\n"
     ]
    }
   ],
   "source": [
    "flancot_path = 'flancot_split/flancot_filtered_15k.jsonl'\n",
    "flancot = pd.read_json(flancot_path, lines=True)\n",
    "# split it into three parts\n",
    "flancot_1 = flancot.sample(len(flancot)//3)\n",
    "flancot_2 = flancot.drop(flancot_1.index).sample(len(flancot)//3)\n",
    "flancot_3 = flancot.drop(flancot_1.index).drop(flancot_2.index)\n",
    "print(len(flancot_1), len(flancot_2), len(flancot_3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save as flancot_split_1, flancot_split_2, flancot_split_3\n",
    "flancot_1.to_json('flancot_split/flancot_split_0.jsonl', orient='records', lines=True)\n",
    "flancot_2.to_json('flancot_split/flancot_split_1.jsonl', orient='records', lines=True)\n",
    "flancot_3.to_json('flancot_split/flancot_split_2.jsonl', orient='records', lines=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "command_r_plus_data = [\n",
    "    \"flancot_split/flancot_split_0-c4ai-command-r-plus-GPTQ-generate_instruct.jsonl\",\n",
    "    \"flancot_split/flancot_split_1-c4ai-command-r-plus-GPTQ-generate_instruct.jsonl\",\n",
    "    \"flancot_split/flancot_split_2-c4ai-command-r-plus-GPTQ-generate_instruct.jsonl\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load them into pandas\n",
    "alpaca_split_0 = pd.read_json(command_r_plus_data[0], lines=True)\n",
    "alpaca_split_1 = pd.read_json(command_r_plus_data[1], lines=True)\n",
    "alpaca_split_2 = pd.read_json(command_r_plus_data[2], lines=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Command-R+\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "option\n",
       "A     5.87%\n",
       "B    14.86%\n",
       "C    16.50%\n",
       "D    62.77%\n",
       "Name: count, dtype: object"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# concatenate them\n",
    "alpaca_split = pd.concat([alpaca_split_0, alpaca_split_1, alpaca_split_2], ignore_index=True)\n",
    "# count the option counts\n",
    "option_counts = alpaca_split['option'].value_counts() / len(alpaca_split) * 100 # percentage\n",
    "# add a precentage sign\n",
    "option_counts = option_counts.apply(lambda x: f\"{x:.2f}%\")\n",
    "# sort by ['A', 'B', 'C', 'D']\n",
    "option_counts = option_counts.reindex(['A', 'B', 'C', 'D'])\n",
    "print('Command-R+')\n",
    "option_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LLama-3-70B-Instruct\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "option\n",
       "A    14.97%\n",
       "B    31.57%\n",
       "C     8.21%\n",
       "D    45.25%\n",
       "Name: count, dtype: object"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llama_3_70b_split_0 = pd.read_json('flancot_split/flancot_filtered_15k-Meta-Llama-3-70B-Instruct-generate_instruct.jsonl', lines=True)\n",
    "\n",
    "option_counts = llama_3_70b_split_0['option'].value_counts() / len(llama_3_70b_split_0) * 100\n",
    "option_counts = option_counts.apply(lambda x: f\"{x:.2f}%\")\n",
    "option_counts = option_counts.reindex(['A', 'B', 'C', 'D'])\n",
    "print('LLama-3-70B-Instruct')\n",
    "option_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>idx</th>\n",
       "      <th>system_prompt</th>\n",
       "      <th>instruction</th>\n",
       "      <th>output</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>You are an AI assistant. User will you give yo...</td>\n",
       "      <td>Translate to Czech:\\n\\nDoctor, something's wro...</td>\n",
       "      <td>Doktore, něco není v pořádku. \\n\\nTranslation ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>You are an AI assistant. User will you give yo...</td>\n",
       "      <td>Deity, which resides in the center of the mand...</td>\n",
       "      <td>El deidad, que reside en el centro del mandala...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>You are an AI assistant. User will you give yo...</td>\n",
       "      <td>Data: Italy LEADER Pietro Grasso; Italy DEMONY...</td>\n",
       "      <td>A possible sentence using this data could be: ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>You are an AI assistant. You will be given a t...</td>\n",
       "      <td>Write an ordered list of reviews about \"seabis...</td>\n",
       "      <td>1. \"Seabiscuit\" is a must-see movie for anyone...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>You should describe the task and explain your ...</td>\n",
       "      <td>Here is a premise:\\nYou will use force to defe...</td>\n",
       "      <td>B) It is not possible to tell.\\n\\nThe premise ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14995</th>\n",
       "      <td>14995</td>\n",
       "      <td>You are an AI assistant. User will you give yo...</td>\n",
       "      <td>Write a tweet that is negative.</td>\n",
       "      <td>As an AI language model, I am programmed to pr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14996</th>\n",
       "      <td>14996</td>\n",
       "      <td>You are an AI assistant that helps people find...</td>\n",
       "      <td>The woman is licking her plate but not necessa...</td>\n",
       "      <td>The reasoning behind this statement is unclear...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14997</th>\n",
       "      <td>14997</td>\n",
       "      <td>You are a helpful assistant, who always provid...</td>\n",
       "      <td>How is \"According to Nick \"Animal\" Culmer, a \"...</td>\n",
       "      <td>Laut Nick \"Animal\" Culmer ist ein \"Nowhere\" ei...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14998</th>\n",
       "      <td>14998</td>\n",
       "      <td>You are a helpful assistant, who always provid...</td>\n",
       "      <td>What is the answer: Which creature appears on ...</td>\n",
       "      <td>The creature that appears on the current Engli...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14999</th>\n",
       "      <td>14999</td>\n",
       "      <td>You are an AI assistant. You will be given a t...</td>\n",
       "      <td>Par ailleurs, l’unité assure le leadership str...</td>\n",
       "      <td>Furthermore, the unit provides strategic leade...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>15000 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         idx                                      system_prompt  \\\n",
       "0          0  You are an AI assistant. User will you give yo...   \n",
       "1          1  You are an AI assistant. User will you give yo...   \n",
       "2          2  You are an AI assistant. User will you give yo...   \n",
       "3          3  You are an AI assistant. You will be given a t...   \n",
       "4          4  You should describe the task and explain your ...   \n",
       "...      ...                                                ...   \n",
       "14995  14995  You are an AI assistant. User will you give yo...   \n",
       "14996  14996  You are an AI assistant that helps people find...   \n",
       "14997  14997  You are a helpful assistant, who always provid...   \n",
       "14998  14998  You are a helpful assistant, who always provid...   \n",
       "14999  14999  You are an AI assistant. You will be given a t...   \n",
       "\n",
       "                                             instruction  \\\n",
       "0      Translate to Czech:\\n\\nDoctor, something's wro...   \n",
       "1      Deity, which resides in the center of the mand...   \n",
       "2      Data: Italy LEADER Pietro Grasso; Italy DEMONY...   \n",
       "3      Write an ordered list of reviews about \"seabis...   \n",
       "4      Here is a premise:\\nYou will use force to defe...   \n",
       "...                                                  ...   \n",
       "14995                    Write a tweet that is negative.   \n",
       "14996  The woman is licking her plate but not necessa...   \n",
       "14997  How is \"According to Nick \"Animal\" Culmer, a \"...   \n",
       "14998  What is the answer: Which creature appears on ...   \n",
       "14999  Par ailleurs, l’unité assure le leadership str...   \n",
       "\n",
       "                                                  output  \n",
       "0      Doktore, něco není v pořádku. \\n\\nTranslation ...  \n",
       "1      El deidad, que reside en el centro del mandala...  \n",
       "2      A possible sentence using this data could be: ...  \n",
       "3      1. \"Seabiscuit\" is a must-see movie for anyone...  \n",
       "4      B) It is not possible to tell.\\n\\nThe premise ...  \n",
       "...                                                  ...  \n",
       "14995  As an AI language model, I am programmed to pr...  \n",
       "14996  The reasoning behind this statement is unclear...  \n",
       "14997  Laut Nick \"Animal\" Culmer ist ein \"Nowhere\" ei...  \n",
       "14998  The creature that appears on the current Engli...  \n",
       "14999  Furthermore, the unit provides strategic leade...  \n",
       "\n",
       "[15000 rows x 4 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_json('flancot/final_15k_data_origin.jsonl', lines=True)\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add an empty column \"input\"\n",
    "data['input'] = ''\n",
    "# save to the same path\n",
    "data.to_json('flancot/final_15k_data_origin.jsonl', lines=True, orient='records')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading data files: 100%|██████████| 2/2 [00:00<00:00, 7605.27it/s]\n",
      "Extracting data files: 100%|██████████| 2/2 [00:00<00:00, 1138.36it/s]\n",
      "Generating train split: 15000 examples [00:00, 492917.88 examples/s]\n",
      "Generating test split: 500 examples [00:00, 62603.42 examples/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['idx', 'system_prompt', 'instruction', 'output', 'input'],\n",
       "        num_rows: 15000\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['idx', 'system_prompt', 'instruction', 'output', 'input'],\n",
       "        num_rows: 500\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "# load the dataset\n",
    "dataset_path = {\n",
    "    'train': 'flancot/final_15k_data_origin.jsonl',\n",
    "    'test': 'lima500_withsys.jsonl',\n",
    "    \n",
    "}\n",
    "dataset = load_dataset('json', data_files=dataset_path)\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "robust",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
